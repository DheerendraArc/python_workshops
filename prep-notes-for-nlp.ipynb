{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Natural Language Processing with Python\n",
    "\n",
    "### What are we covering today?\n",
    "- What is NLP?\n",
    "- Options for NLP in Python\n",
    "- Word tokenization\n",
    "- Sentence tokenization\n",
    "- Noun phrase extraction\n",
    "- Part of Speech Tagging\n",
    "- Find all nouns\n",
    "- Word transformations (lemmatization, pluralization)\n",
    "- Look for sentences of particular lengths\n",
    "- Sentiment Analysis\n",
    "\n",
    "\n",
    "TODO: What is NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Natural language processing with Python is so much fun!\"\n",
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Natural', 'language', 'processing', 'with', 'Python', 'is', 'so', 'much', 'fun'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('so', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('fun', 'NN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural JJ\n",
      "language NN\n",
      "processing NN\n",
      "with IN\n",
      "Python NNP\n",
      "is VBZ\n",
      "so RB\n",
      "much JJ\n",
      "fun NN\n"
     ]
    }
   ],
   "source": [
    "for word, pos in blob.tags:\n",
    "    print(word, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what these tags mean, you might check out http://www.clips.ua.ac.be/pages/mbsp-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['natural language processing', 'python'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para = \"Here is my first sentence. I am really sad. People are so angry. Life is fantastic. It's really awesome to have three sentences though.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob2 = TextBlob(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Here is my first sentence.\"),\n",
       " Sentence(\"I am really sad.\"),\n",
       " Sentence(\"People are so angry.\"),\n",
       " Sentence(\"Life is fantastic.\"),\n",
       " Sentence(\"It's really awesome to have three sentences though.\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.2375, subjectivity=0.30000000000000004)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.25, subjectivity=0.3333333333333333)\n",
      "Sentiment(polarity=-0.5, subjectivity=1.0)\n",
      "Sentiment(polarity=-0.5, subjectivity=1.0)\n",
      "Sentiment(polarity=0.4, subjectivity=0.9)\n",
      "Sentiment(polarity=1.0, subjectivity=1.0)\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob2.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is my first sentence. 0.25\n",
      "I am really sad. -0.5\n",
      "People are so angry. -0.5\n",
      "Life is fantastic. 0.4\n",
      "It's really awesome to have three sentences though. 1.0\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob2.sentences:\n",
    "    print(sentence, sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'languages'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[1].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent2 = \"Squids are huge with many tentacles.\"\n",
    "blob3 = TextBlob(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob3.words[1].lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tentacle'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob3.words[-1].lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Squids/NNP/B-NP/O are/VBP/B-VP/O huge/JJ/B-ADJP/O with/IN/B-PP/B-PNP many/JJ/B-NP/I-PNP tentacles/NNS/I-NP/I-PNP ././O/O'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob3.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"octopi\")\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('His', 0.7117826487905228), ('This', 0.28821735120947717)]\n",
      "[('is', 1.0)]\n",
      "[('poor', 0.9626865671641791), ('poorly', 0.03731343283582089)]\n",
      "[('spelled', 1.0)]\n",
      "[('word', 0.8948948948948949), ('ward', 0.03903903903903904), ('rd', 0.03003003003003003), ('wry', 0.015015015015015015), ('ord', 0.009009009009009009), ('wad', 0.006006006006006006), ('wid', 0.003003003003003003), ('wed', 0.003003003003003003)]\n"
     ]
    }
   ],
   "source": [
    "bad_text = \"This is poory spelled wrd\"\n",
    "blob4 = TextBlob(bad_text)\n",
    "for word in blob4.words:\n",
    "    print(word.spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repetitive = \"John likes to drink sweet Soda. Jane also likes soda. John and Jane both like soda.\"\n",
    "blob5 = TextBlob(repetitive)\n",
    "blob5.word_counts['soda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob5.words.count('soda', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob5.noun_phrases.count('john')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textblob can also handle some translation and language detection. Do we want to talk about that at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['John', 'likes', 'to']),\n",
       " WordList(['likes', 'to', 'drink']),\n",
       " WordList(['to', 'drink', 'sweet']),\n",
       " WordList(['drink', 'sweet', 'Soda']),\n",
       " WordList(['sweet', 'Soda', 'Jane']),\n",
       " WordList(['Soda', 'Jane', 'also']),\n",
       " WordList(['Jane', 'also', 'likes']),\n",
       " WordList(['also', 'likes', 'soda']),\n",
       " WordList(['likes', 'soda', 'John']),\n",
       " WordList(['soda', 'John', 'and']),\n",
       " WordList(['John', 'and', 'Jane']),\n",
       " WordList(['and', 'Jane', 'both']),\n",
       " WordList(['Jane', 'both', 'like']),\n",
       " WordList(['both', 'like', 'soda'])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob5.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.35, subjectivity=0.65)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "blob6 = TextBlob(repetitive)\n",
    "for sentence in blob6.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='neg', p_pos=0.3519319302860903, p_neg=0.6480680697139108)\n",
      "Sentiment(classification='neg', p_pos=0.43530881093370977, p_neg=0.564691189066291)\n",
      "Sentiment(classification='neg', p_pos=0.4908744687646318, p_neg=0.5091255312353682)\n"
     ]
    }
   ],
   "source": [
    "blob7 = TextBlob(repetitive, analyzer=NaiveBayesAnalyzer())\n",
    "for sentence in blob7.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Is it worth showing how to use different tokenizers, noun phrase chunks, POS taggers, etc...? Should we show how to assemble a Blobbler for re-use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "sent = \"John hates soda\"\n",
    "blob7 = TextBlob(sent)\n",
    "for sentence in blob7.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='neg', p_pos=0.22370657856753343, p_neg=0.7762934214324665)\n"
     ]
    }
   ],
   "source": [
    "sent = \"John hates soda\"\n",
    "blob8 = TextBlob(sent, analyzer=NaiveBayesAnalyzer())\n",
    "for sentence in blob8.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg length of sentence\n",
    "Richness: number of words / number of diff words\n",
    "\n",
    "Get speech from Clinton, Bush, Obama, Trump\n",
    "Do avg grad level of text: Flesch-Kincaid score\n",
    "\n",
    "https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
    "\n",
    "https://en.wikipedia.org/wiki/Automated_readability_index\n",
    "\n",
    "https://pypi.python.org/pypi/textstat/\n",
    "\n",
    "After calculating our own, could then use textstat to get Flesch-Kincaid as a comparison to the word/sentence approaches. Flesch-Kincaid uses syllables. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text]",
   "language": "python",
   "name": "conda-env-text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
