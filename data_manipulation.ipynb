{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Python for the Humanities and Social Sciences <br> *Data Manipulation* </h1>\n",
    "\n",
    "## Info\n",
    "- Scott Bailey (CIDR), *scottbailey@stanford.edu*\n",
    "- Javier de la Rosa (CIDR), *versae@stanford.edu*\n",
    "- Ashley Jester (CIDR/SSDS), *ajester@stanford.edu*\n",
    "- Green Library 121A, 2pm-4pm\n",
    "\n",
    "## Topics\n",
    "- Pandas Series and DataFrame (numpy, scipy)\n",
    "- Loading data in, null and missing data\n",
    "- Describing data\n",
    "- Column manipulation\n",
    "- String manipulation (super basic regex)\n",
    "- Split-Apply-Combine\n",
    "- Plotting (matplotlib, seaborn):\n",
    "  - Basic charts (line, bar, pie)\n",
    "  - Histograms\n",
    "  - Scatter plots\n",
    "  - Boxplots, violinplots\n",
    "\n",
    "### Virtual environments (venvs) and Anaconda\n",
    "- Isolated environment so each project can have its own dependencies without conflicts with other projects\n",
    "- Anaconda has its own environment manager and package manager, let's you easily set Python versions, and comes with many of the standard packages used in scientific computing\n",
    "\n",
    "To set up the environment for this project, in your BASH shell, run (`$` means a shell command):\n",
    "\n",
    "```\n",
    "$ conda create -n data python=3.5 anaconda seaborn\n",
    "```\n",
    "\n",
    "Or installing the specific packages we'll be using:\n",
    "\n",
    "```\n",
    "$ conda create -n data python=3.5\n",
    "$ conda install -n data jupyter pandas numpy scipy matplotlib seaborn requests\n",
    "```\n",
    "\n",
    "This creates an environment named `data`, where the python version is specified to 3.5, and installs the necessary packages for data exploration and manipulation in the environment.\n",
    "\n",
    "After you create the environment, run `source activate data` or `activate data` depending on whether you are on OSX or Windows to activate the environment.\n",
    "\n",
    "### Jupyter Notebooks\n",
    "- Used to be IPython Notebooks\n",
    "- Write and evaluate code at a granular level without rerunning scripts constantly and using a lot of print debugging\n",
    "- Mix in Markdown and HTML within your notebook, and so is a great way of presenting code and data analysis\n",
    "\n",
    "Once you have a virtual environment running, just run `jupyter notebook` from the location where you want to store your notebook.\n",
    "\n",
    "```\n",
    "$ jupyter notebook\n",
    "```\n",
    "\n",
    "And go to http://localhost:8888/ in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "From Jake Vanderplas' book [**Python Data Science Handbook**](http://shop.oreilly.com/product/0636920034919.do) (from which some code excerpts are used in this workshop):\n",
    "\n",
    "> Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a `DataFrame`. `DataFrame`s are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data. As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Set some options\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main data structures in Pandas: `Series`, `DataFrame`, and `Index`. Pandas has a very decent [documentation](http://pandas.pydata.org/pandas-docs/stable/), and using Jupyter, any method help can be shown by appending the a `?` to the end and running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For example\n",
    "pd.isnull?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Series`\n",
    "A `Series` is a one-dimensional array of indexed data. It can be seens as a specialized dictionary or a generalized NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 3, 4], index=[\"a\", \"b\", \"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series({\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 3, 4], index=[\"a\", \"b\", \"c\", \"d\"]) == pd.Series({\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accessing elements\n",
    "s = pd.Series([1, 2, 3, 4], index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "s[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[\"b\":\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NumPy array underneath\n",
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With an index\n",
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame`\n",
    "\n",
    "A `DataFrame` is a two-dimensional array with both flexible row indices and flexible column names. It can be seen as \n",
    "as a generalization of a two-dimensional NumPy array, or a specialization of a dictionary in which each column name maps to a `Series` of column data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521, 'Texas': 26448193, 'New York': 19651127,\n",
    "                   'Florida': 19552860, 'Illinois': 12882135}\n",
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "states = pd.DataFrame({'population': population_dict, 'area': area_dict})\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population = pd.Series(population_dict)\n",
    "area = pd.Series(area_dict)\n",
    "pd.DataFrame({'population': population, 'area': area})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index\n",
    "states.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Values\n",
    "states.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Columns\n",
    "states.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrames` can be created in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From regular dictionaries\n",
    "data = {'column A': [1,2,3,4], 'column B': list('abcd')}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From lists\n",
    "data = [(1,'a'),(2,'b'),(3,'c'),(4,'d')]\n",
    "labels = ['ColumnA','ColumnB']\n",
    "pd.DataFrame.from_records(data, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Acts like a Python set() that supports duplicated items\n",
    "\"California\" in states.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides a few methods to load in and out data in CSVs, Excel spreadsheets, HDF, or even JSON format.\n",
    "\n",
    "For example, click in the next URL of a CSV file containing twitter data during the release of the Apple Watch: http://bit.ly/python_workshop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas can even fetch data from a URL\n",
    "pd.read_csv(\"http://bit.ly/python_workshop_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the previous data to a locala file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"twitter.csv\", \"wb\") as file:\n",
    "    file.write(requests.get(\"http://bit.ly/python_workshop_data\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Showing the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reload the CSV but this time specifying a index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"twitter.csv\", index_col=\"created_at\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also filter out some columns we are not interested, provide data types for a couple, and show the first 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"created_at\", \"id\", \"lang\", \n",
    "    \"place\", \"possibly_sensitive\", \"text\",\n",
    "    \"user_screen_name\", \"user_name\", \"user_lang\", \"user_location\",\n",
    "    \"hashtags\", \"media\", \"symbols\", \"urls\", \"lat\", \"lon\", \"country\"]\n",
    "index = \"created_at\"\n",
    "data_types = {\n",
    "    \"id\": int,\n",
    "    \"possibly_sensitive\": bool,\n",
    "    \"lat\": float,\n",
    "    \"lon\": float,\n",
    "}\n",
    "df = pd.read_csv(\"twitter.csv\", parse_dates=[\"created_at\"], index_col=\"created_at\", usecols=columns, dtype=data_types)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's find out the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can get rid of those ugly `NaN`s (which is the Pandas way of telling that not valid data has been found in a cell). We'll first drop rows with just `NaN`s and then fill those of type string with am empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nans = {col: \"\" for col in [\"lang\", \"place\", \"text\", \"user_screen_name\", \"user_name\", \"user_lang\",\n",
    "                            \"user_location\", \"hashtags\", \"media\", \"symbols\", \"urls\", \"country\"]}\n",
    "df.fillna(value=nans, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "previous_count = df.count()  # .count() basically counts elements\n",
    "df = df.dropna(subset=[\"id\"]).dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also remove duplicate rows based on all cell content or individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"id\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "previous_count.id, df.count().id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just save the clean data to any format supported by Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"twitter_clean.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states[\"population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can create a \"mask\"\n",
    "states.population > 3e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And filter based on any logical expression\n",
    "states[states.population > 3e7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also with *fancy* indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states[[\"population\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(states[\"population\"]), type(states[[\"population\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Area of states with population higher than 30000000 people\n",
    "states[states.population > 3e7][[\"area\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It's also possible to access individual row data\n",
    "states.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.loc[\"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.ix[\"California\", \"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most basic operations you can do with data is counting. Let's try to get the how many times each hashtag is present in the twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[[\"hashtags\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using string operations we can `.split()` by comma and get a list of hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.hashtags.dropna().str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Equivalent to\n",
    "df.hashtags.dropna().apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now *sum* all those lists together and create a `Series` with the that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.hashtags.dropna().str.split(\",\").sum()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = pd.Series(df.hashtags.dropna().str.split(\",\").sum())\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One handy function of Pandas is `.value_counts()` which unsurprisingly counts how many times an element is present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, this is not the fastest way to do this. Python's stantard library `collections` are out of the scope of this workshop, but its `Counter` class is commonly use for the same purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(\",\".join(df.hashtags.dropna().values).split(\",\")).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same pattern can be apply to `symbols`, `media`, or `urls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in [\"symbols\", \"media\", \"urls\"]:\n",
    "    column_series = pd.Series(df[column].dropna().str.split(\",\").sum())\n",
    "    print(column)\n",
    "    print(column_series.value_counts()[:10])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data\n",
    "\n",
    "But what about the most tweeted language? Or the most prolific user? For this kind of operations we need to use what is called an [Split-Apply-Combine](https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf) approach. In Pandas this can take the form of a `.groupby()` operation followed by an `.aggregate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(\"lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(\"lang\")[[\"text\"]]  # no computation is made yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(\"lang\")[[\"text\"]].aggregate(np.count_nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort by text\n",
    "df.groupby(\"lang\")[[\"text\"]].aggregate(np.count_nonzero).sort_values(\"text\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same pattern can be applied to `user_screen_name`, `place`, or `country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_by(df, column, by=\"text\", count=10):\n",
    "    return (df.groupby(column)[[by]]\n",
    "              .aggregate(np.count_nonzero).sort_values(by, ascending=False)[:count])\n",
    "\n",
    "count_by(df, \"user_screen_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_by(df[df.place.str.len() > 0], \"place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_by(df[df.country.str.len() > 0], \"country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for complex groupings like this a pivot table can be more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.pivot_table(\n",
    "    index=[\"lang\", \"user_screen_name\"],\n",
    "    values=[\"text\"],\n",
    "    aggfunc=np.count_nonzero\n",
    ").sort_values(\"text\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just out of curiosity, what's the average length of the tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"len\"] = df.text.apply(len)\n",
    "df[\"len\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get the most popular retweet in the English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_text = df[df['lang'] == 'en'][['text']]\n",
    "en_retweets = en_text[en_text.text.str.startswith(\"RT @\")]\n",
    "count_by(en_retweets, \"text\", count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several libraries to handle visualization of data in Python. `matplotlib` is probably the most widely used and also the most intricate to learn. For that reason some replacements and wrappers extending it have appeared over the years, the most prominent one being `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enables inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "ax.plot(x, np.sin(x))\n",
    "ax.plot(x, np.cos(x))\n",
    "# Besides this object-oriented paradigm, matplotlib also provides MATLAB-based syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other styles available as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "    ax.plot(x, np.sin(x))\n",
    "    ax.plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Even a special one for XKCD!\n",
    "with plt.xkcd():\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "    ax.plot(x, np.sin(x))\n",
    "    ax.plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`seaborn` changes the default style after being imported, but it can be reverted back easily setting the default style to `classic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "ax.plot(x, np.sin(x))\n",
    "ax.plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also provides some utilities to create basic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "count_by(df, \"lang\").plot(ax=ax,\n",
    "    kind=\"bar\",\n",
    ")\n",
    "ax.set_title(\"Languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a hitogram with the lengths of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "df[\"len\"].hist(ax=ax, bins=15, normed=True, color='lightseagreen')\n",
    "df[\"len\"].plot(ax=ax, kind='kde', xlim=(0, 150), style='r--')\n",
    "ax.set_title(\"Histogram of lengths of tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.boxplot(column=\"len\", grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to find out if there is any sort of relationship between the length of a tweet and the number of hastags it uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"hashtags_count\"] = df.hashtags.apply(lambda x: len(x.split(\",\")))\n",
    "df[[\"len\", \"hashtags_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15, 5))\n",
    "ax.scatter(df.hashtags_count, df.len)\n",
    "ax.set_ylabel(\"Length\")\n",
    "ax.set_xlabel(\"# Hashtags\")\n",
    "ax.set_title(\"Tweets length by number of hashtags\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
